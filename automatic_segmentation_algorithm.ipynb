{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#segmentation할 data의 경로\n",
        "\n",
        "segmentation을 수행할 데이터의 경로를 data_dir에 입력하세요."
      ],
      "metadata": {
        "id": "gdvsfdCu1PAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTW7zrqOBGei",
        "outputId": "7deaa1a7-48b5-46c2-a8a3-ba2d44d8a6a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DkkGrA6agUn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3da936de-fc48-4f4c-f8e4-311630ebc598"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "경로 존재\n"
          ]
        }
      ],
      "source": [
        "# segementation 수행할 데이터 경로\n",
        "data_dir = '/content/drive/MyDrive/HUFS/Digital_image_processing/project/brats18_test'\n",
        "\n",
        "# output file을 저장할 경로 설정\n",
        "outdir = '/content/drive/MyDrive/HUFS/Digital_image_processing/project/segmentation_result'\n",
        "\n",
        "import os\n",
        "\n",
        "if os.path.exists(data_dir):    # 지정된 경로가 존재하는지 여부를 확인\n",
        "    print(\"경로 존재\")\n",
        "else:\n",
        "    print(\"경로 존재X\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#segmentaion수행"
      ],
      "metadata": {
        "id": "QvIBidY1_nME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set up environment\n",
        "\n",
        "!pip install monai-weekly\n",
        "#!pip install pytorch-ignite\n",
        "#!pip install tmp\n",
        "\n",
        "import logging\n",
        "import sys\n",
        "import shutil\n",
        "import time\n",
        "import tmp\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import monai\n",
        "from monai.config import print_config\n",
        "from monai.data import CacheDataset, DataLoader, Dataset,ArrayDataset\n",
        "from monai.transforms import (\n",
        "    LoadImaged,\n",
        "    AddChanneld,\n",
        "    NormalizeIntensityd,\n",
        "    ToTensord,\n",
        "    #ResizeWithPadOrCropd,\n",
        "    #RandFlipd,\n",
        "    #EnsureChannelFirst,\n",
        "    #EnsureChannelFirstd,\n",
        "    #AsDiscrete,\n",
        "    #SpatialCropd,\n",
        "    #RandCropByPosNegLabeld,\n",
        "    #RandSpatialCropd,\n",
        "    #RandSpatialCropSamplesd,\n",
        "    #CropForeground,\n",
        "    #CropForegroundd,\n",
        "    #RandGaussianNoised,\n",
        "    #Spacing,\n",
        "    #Spacingd,\n",
        "    #AddChannel,\n",
        "    #Compose,\n",
        "    #LoadImage,\n",
        "    #Resize,\n",
        "    #EnsureType,\n",
        "    #Randomizable,\n",
        "    #LoadImaged,\n",
        "    #EnsureType,\n",
        "    #EnsureTyped,\n",
        "    #AddChanneld,\n",
        "    #RandAffined,\n",
        "    #Resized,\n",
        "    #RandShiftIntensityd,\n",
        "    #ScaleIntensityRanged,\n",
        "    #ScaleIntensityRange,\n",
        "    #MapTransform,\n",
        "    #RandSpatialCropd,\n",
        "    #CenterSpatialCropd,\n",
        "    #Orientationd,\n",
        "    #Invertd,\n",
        "    #AsDiscreted\n",
        ")\n",
        "\n",
        "from monai.data import DataLoader\n",
        "from monai.networks.nets import UNet\n",
        "from monai.data import CacheDataset, DataLoader, Dataset\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.networks.layers import Norm\n",
        "import glob\n",
        "import nibabel as nib\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "print_config()\n",
        "\n",
        "# test_set 준비\n",
        "\n",
        "test_images = sorted(\n",
        "    glob.glob(os.path.join(data_dir, \"Brats18_test_*\", \"t1ce.nii.gz\")))\n",
        "\n",
        "test_files = [\n",
        "    {\"image\": image_name}\n",
        "    for image_name in (test_images)\n",
        "]\n",
        "\n",
        "test_transforms = Compose(\n",
        "    [\n",
        "        LoadImaged(keys=[\"image\", \"label\"]),\n",
        "        AddChanneld(keys=[\"image\", \"label\"]),\n",
        "        NormalizeIntensityd(keys=[\"image\"], nonzero=True, channel_wise=True),\n",
        "        ToTensord(keys=[\"image\", \"label\"]),\n",
        "    ]\n",
        ")\n",
        "\n",
        "test_ds = CacheDataset(\n",
        "    data=test_files, transform=test_transforms, cache_rate=1.0, num_workers=4)\n",
        "\n",
        "test_loader = DataLoader(test_ds, batch_size=1, num_workers=4)\n",
        "\n",
        "device = torch.device(\"cuda:0\")\n",
        "model = UNet(\n",
        "    dimensions=3,\n",
        "    in_channels=1,\n",
        "    out_channels=2,\n",
        "    channels=(16, 32, 64, 128, 256),\n",
        "    strides=(2, 2, 2, 2),\n",
        "    num_res_units=2,\n",
        "    norm=Norm.BATCH,\n",
        ").to(device)\n",
        "\n",
        "# evaluation\n",
        "model.load_state_dict(torch.load(\n",
        "    os.path.join(data_dir, \"best_metric_model06748.pth\")))\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, test_data in enumerate(test_loader):\n",
        "        roi_size = (64, 64, 32)\n",
        "        sw_batch_size = 16\n",
        "        test_outputs = sliding_window_inference(\n",
        "            test_data[\"image\"].to(device), roi_size, sw_batch_size, model, overlap=0.42\n",
        "        )\n",
        "        plt.figure(\"check\", (18, 6))\n",
        "        plt.subplot(2, 2, 1)\n",
        "        plt.title(f\"image {i}\")\n",
        "        plt.imshow(torch.sum(test_data[\"image\"][0, 0, :, :, :],dim=1), cmap=\"gray\",aspect=1/4)\n",
        "        plt.subplot(2, 2, 2)\n",
        "        plt.title(f\"output {i}\")\n",
        "        plt.imshow(torch.amax(torch.argmax(test_outputs.cpu(), dim=1)[0, :, :, :],dim=1),aspect=1/4)\n",
        "        plt.subplot(2, 2, 3)\n",
        "        plt.title(f\"image {i}\")\n",
        "        plt.imshow(torch.sum(test_data[\"image\"][0, 0, :, :, :],dim=0), cmap=\"gray\",aspect=1/4)\n",
        "        plt.subplot(2, 2, 4)\n",
        "        plt.title(f\"output {i}\")\n",
        "        plt.imshow(torch.amax(torch.argmax(test_outputs.cpu(), dim=0)[0, :, :, :],dim=0),aspect=1/4)\n",
        "        plt.show()\n",
        "\n",
        "        # output파일 저장\n",
        "        h2 = nib.Nifti1Image(torch.argmax(test_outputs.cpu(), dim=1).numpy().squeeze().astype('float32'),test_data['image_meta_dict']['affine'][0].numpy())\n",
        "        nib.save(h2,os.path.join(outdir,f\"{test_files[i].get('image').split('/')[-2]}.nii.gz\"))"
      ],
      "metadata": {
        "id": "O-MvToGmCB97"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}